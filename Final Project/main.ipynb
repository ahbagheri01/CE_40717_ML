{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1a5120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - train Loss: 1.572e+02 - train Acc: 65.53%: 100%|█| 293/293 [00:13<00:0\n",
      "epoch 0 - val Loss: 6.322e-01 - val Acc: 53.99%: 100%|█| 98/98 [00:01<00:00, 83.\n",
      "epoch 1 - train Loss: 1.491e+02 - train Acc: 68.63%: 100%|█| 293/293 [00:14<00:0\n",
      "epoch 1 - val Loss: 5.351e-01 - val Acc: 69.12%: 100%|█| 98/98 [00:00<00:00, 98.\n",
      "epoch 2 - train Loss: 1.457e+02 - train Acc: 69.12%: 100%|█| 293/293 [00:14<00:0\n",
      "epoch 2 - val Loss: 6.543e-01 - val Acc: 60.20%: 100%|█| 98/98 [00:01<00:00, 86.\n",
      "epoch 3 - train Loss: 1.445e+02 - train Acc: 69.46%: 100%|█| 293/293 [00:14<00:0\n",
      "epoch 3 - val Loss: 5.503e-01 - val Acc: 65.09%: 100%|█| 98/98 [00:00<00:00, 101\n",
      "epoch 4 - train Loss: 1.421e+02 - train Acc: 70.07%: 100%|█| 293/293 [00:13<00:0\n",
      "epoch 4 - val Loss: 5.899e-01 - val Acc: 69.12%: 100%|█| 98/98 [00:01<00:00, 93.\n",
      "epoch 5 - train Loss: 1.408e+02 - train Acc: 70.05%: 100%|█| 293/293 [00:13<00:0\n",
      "epoch 5 - val Loss: 6.304e-01 - val Acc: 64.63%: 100%|█| 98/98 [00:00<00:00, 110\n",
      "epoch 6 - train Loss: 1.396e+02 - train Acc: 70.27%: 100%|█| 293/293 [00:14<00:0\n",
      "epoch 6 - val Loss: 5.974e-01 - val Acc: 65.93%: 100%|█| 98/98 [00:00<00:00, 105\n",
      "epoch 7 - train Loss: 1.396e+02 - train Acc: 70.30%: 100%|█| 293/293 [00:16<00:0\n",
      "epoch 7 - val Loss: 5.754e-01 - val Acc: 66.88%: 100%|█| 98/98 [00:01<00:00, 83.\n",
      "epoch 8 - train Loss: 1.376e+02 - train Acc: 70.90%: 100%|█| 293/293 [00:15<00:0\n",
      "epoch 8 - val Loss: 5.689e-01 - val Acc: 69.85%: 100%|█| 98/98 [00:01<00:00, 89.\n",
      "epoch 9 - train Loss: 1.366e+02 - train Acc: 71.17%: 100%|█| 293/293 [00:14<00:0\n",
      "epoch 9 - val Loss: 6.368e-01 - val Acc: 58.40%: 100%|█| 98/98 [00:01<00:00, 81.\n",
      "epoch 10 - train Loss: 1.353e+02 - train Acc: 71.26%: 100%|█| 293/293 [00:14<00:\n",
      "epoch 10 - val Loss: 5.904e-01 - val Acc: 67.03%: 100%|█| 98/98 [00:01<00:00, 77\n",
      "epoch 11 - train Loss: 1.348e+02 - train Acc: 71.62%: 100%|█| 293/293 [00:17<00:\n",
      "epoch 11 - val Loss: 6.040e-01 - val Acc: 67.22%: 100%|█| 98/98 [00:01<00:00, 92\n",
      "epoch 12 - train Loss: 1.330e+02 - train Acc: 71.80%: 100%|█| 293/293 [00:18<00:\n",
      "epoch 12 - val Loss: 6.231e-01 - val Acc: 63.95%: 100%|█| 98/98 [00:00<00:00, 11\n",
      "epoch 13 - train Loss: 1.331e+02 - train Acc: 71.82%: 100%|█| 293/293 [00:14<00:\n",
      "epoch 13 - val Loss: 6.019e-01 - val Acc: 67.32%: 100%|█| 98/98 [00:01<00:00, 88\n",
      "epoch 14 - train Loss: 1.324e+02 - train Acc: 71.90%: 100%|█| 293/293 [00:14<00:\n",
      "epoch 14 - val Loss: 6.018e-01 - val Acc: 67.70%: 100%|█| 98/98 [00:00<00:00, 10\n",
      "epoch 15 - train Loss: 1.326e+02 - train Acc: 71.84%: 100%|█| 293/293 [00:18<00:\n",
      "epoch 15 - val Loss: 6.088e-01 - val Acc: 65.24%: 100%|█| 98/98 [00:01<00:00, 79\n",
      "epoch 16 - train Loss: 1.313e+02 - train Acc: 72.43%: 100%|█| 293/293 [00:19<00:\n",
      "epoch 16 - val Loss: 6.276e-01 - val Acc: 68.08%: 100%|█| 98/98 [00:00<00:00, 98\n",
      "epoch 17 - train Loss: 1.324e+02 - train Acc: 71.83%: 100%|█| 293/293 [00:19<00:\n",
      "epoch 17 - val Loss: 6.019e-01 - val Acc: 68.49%: 100%|█| 98/98 [00:00<00:00, 10\n",
      "epoch 18 - train Loss: 1.304e+02 - train Acc: 72.53%: 100%|█| 293/293 [00:17<00:\n",
      "epoch 18 - val Loss: 6.247e-01 - val Acc: 67.24%: 100%|█| 98/98 [00:00<00:00, 10\n",
      "epoch 19 - train Loss: 1.311e+02 - train Acc: 72.18%: 100%|█| 293/293 [00:16<00:\n",
      "epoch 19 - val Loss: 6.019e-01 - val Acc: 68.43%: 100%|█| 98/98 [00:01<00:00, 83\n",
      "epoch 20 - train Loss: 1.305e+02 - train Acc: 72.47%: 100%|█| 293/293 [00:15<00:\n",
      "epoch 20 - val Loss: 6.086e-01 - val Acc: 67.78%: 100%|█| 98/98 [00:00<00:00, 10\n",
      "epoch 21 - train Loss: 1.300e+02 - train Acc: 72.71%: 100%|█| 293/293 [00:15<00:\n",
      "epoch 21 - val Loss: 6.178e-01 - val Acc: 66.91%: 100%|█| 98/98 [00:01<00:00, 86\n",
      "parametrs : {'NUMBER_OF_EPOCHS': 22, 'loss_function': 'nn.CrossEntropyLoss', 'optimizer': 'Adam', 'lr': 0.01, 'step_size': 10, 'gamma': 0.1, 'BATCH_SIZE': 256, 'mlp_hidden_dims': [500, 400, 300, 200, 100, 100], 'column_idx': {'product_age_group': 0, 'device_type': 1, 'partner_id': 2, 'audience_id': 3, 'product_gender': 4, 'product_category(1)': 5, 'product_country': 6, 'day_time_category': 7, 'nb_clicks_1week': 8}, 'embeddings_input': [('product_age_group', 9, 9), ('device_type', 4, 4), ('partner_id', 184, 100), ('audience_id', 3182, 100), ('product_gender', 11, 11), ('product_category(1)', 22, 22), ('product_country', 17, 17), ('day_time_category', 25, 25)], 'mlp_dropout': [0.2, 0.3, 0.2, 0.2, 0.2, 0.2], 'continuous_cols': ['nb_clicks_1week'], 'mlp_batchnorm': True, 'pred_dim': 2}\n",
      "f1 : 0.33395056758715075\n",
      "acc : 0.66908\n",
      "recall 0.22889305816135083\n",
      "precision : 0.6172619047619048            \n",
      "f1t : 0.42567441860465116\n",
      "acct : 0.71188\n",
      "recallt 0.29307568438003223\n",
      "precisiont : 0.7774002524026794\n",
      "content/Recommendation\n",
      "2022/02/09 11:59:26 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n",
      "2022/02/09 11:59:26 INFO mlflow.pyfunc.backend: === Running command 'gunicorn --timeout=60 -b 0.0.0.0:8080 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2022-02-09 11:59:26 +0330] [24970] [INFO] Starting gunicorn 20.1.0\n",
      "[2022-02-09 11:59:26 +0330] [24970] [INFO] Listening at: http://0.0.0.0:8080 (24970)\n",
      "[2022-02-09 11:59:26 +0330] [24970] [INFO] Using worker: sync\n",
      "[2022-02-09 11:59:26 +0330] [24971] [INFO] Booting worker with pid: 24971\n",
      "{'column_idx': '/home/amirhoosein/Documents/term5/ML/Project/ML_Project/mlruns/4/4eb689e3be564e7da0bb4d598633d125/artifacts/content/Recommendation/artifacts/column_idx.pkl', 'cont_cols': '/home/amirhoosein/Documents/term5/ML/Project/ML_Project/mlruns/4/4eb689e3be564e7da0bb4d598633d125/artifacts/content/Recommendation/artifacts/cont_cols.pkl', 'embeddings_input': '/home/amirhoosein/Documents/term5/ML/Project/ML_Project/mlruns/4/4eb689e3be564e7da0bb4d598633d125/artifacts/content/Recommendation/artifacts/embeddings_input.pkl', 'state_dict_model': '/home/amirhoosein/Documents/term5/ML/Project/ML_Project/mlruns/4/4eb689e3be564e7da0bb4d598633d125/artifacts/content/Recommendation/artifacts/modelD.pt'}\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f4e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import sklearn\n",
    "import json\n",
    "import torch\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import Preprocess as ps\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import torch\n",
    "from urllib.parse import urlparse\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import DWModels as MD\n",
    "import Preprocess as ps\n",
    "import tqdm\n",
    "import logging\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "import ML_train as tr\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "state_dict_path = f'content/modelD.pt'\n",
    "column_idx_path = f'content/column_idx.pkl'\n",
    "embeddings_input_path = f'content/embeddings_input.pkl'\n",
    "cont_cols_path = f'content/cont_cols.pkl'\n",
    "model_path = f\"content/Recommendation\"\n",
    "artifacts = {\n",
    "    \"state_dict_model\": state_dict_path,\n",
    "    \"column_idx\": column_idx_path,\n",
    "    \"embeddings_input\": embeddings_input_path,\n",
    "    \"cont_cols\":cont_cols_path\n",
    "}\n",
    "conda_env = {\n",
    "    'channels': ['defaults'],\n",
    "    'dependencies': [\n",
    "            f'python=3.9.7',\n",
    "      {\n",
    "          'pip':[\n",
    "            f'mlflow=={mlflow.__version__}',\n",
    "            f'torch=={torch.__version__}',\n",
    "            f'numpy=={np.__version__}',\n",
    "            f'sklearn == {sklearn.__version__}'\n",
    "    ]\n",
    "      }\n",
    "    ],\n",
    "    'name': 'Recommendation'\n",
    "}\n",
    "class ModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "  def load_context(self, context):\n",
    "    import DWModels as MD\n",
    "    import Preprocess as ps\n",
    "    import torch\n",
    "    self._p = ps.preprocess()\n",
    "\n",
    "    # Load in and deserialize the embeddings\n",
    "    print(context.artifacts)\n",
    "    with open(context.artifacts[\"column_idx\"], 'rb') as handle:\n",
    "      self._column_idx = pickle.load(handle)\n",
    "    \n",
    "    # load in and deserialize the model tokenizer\n",
    "    with open(context.artifacts[\"embeddings_input\"], 'rb') as handle:\n",
    "      self._embeddings_input = pickle.load(handle)\n",
    "    \n",
    "    with open(context.artifacts[\"cont_cols\"], 'rb') as handle:\n",
    "      self._cont_cols = pickle.load(handle)\n",
    "\n",
    "    model = MD.TabMlp(\n",
    "    mlp_hidden_dims=[500,400,300,200, 100, 100],\n",
    "    column_idx=self._column_idx,\n",
    "    embed_input=self._embeddings_input,\n",
    "    mlp_dropout=[0.2,0.3,0.2,0.2,0.2,0.2],\n",
    "    continuous_cols=self._cont_cols,\n",
    "    mlp_batchnorm=True,\n",
    "    pred_dim = 2)\n",
    "    \n",
    "    self._model = model\n",
    "    self._model.load_state_dict(torch.load(context.artifacts[\"state_dict_model\"]))\n",
    "    self._model.eval()\n",
    "    \n",
    "  def predict(self, context, input_model):\n",
    "    input_m = torch.Tensor(self._p.prepro_test(input_model))\n",
    "    output = self._model(input_m)\n",
    "    predicted = torch.max(output.data,1)[1]\n",
    "    return predicted.numpy()\n",
    "\n",
    "def startModel():\n",
    "    f = open('model_run.txt', mode='rt')\n",
    "    run_id = f.read()\n",
    "    model_name = \"model\"\n",
    "    if run_id == \"\":\n",
    "        name = f'Recommendation Model'\n",
    "        try:\n",
    "            experiment_id = mlflow.get_experiment_by_name(name).experiment_id\n",
    "        except:\n",
    "            experiment_id = mlflow.create_experiment(name)\n",
    "        mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        data = pd.read_csv('PreModule/datasets/train_dataset.csv')\n",
    "        p = ps.preprocess()\n",
    "\n",
    "        y,X,column_idx,embeddings_input,cont_cols = p.prepro_train(data)\n",
    "\n",
    "        mlp_hidden_dims=[500,400,300,200, 100, 100]\n",
    "        column_idx=column_idx\n",
    "        embed_input=embeddings_input\n",
    "        mlp_dropout=[0.2,0.3,0.2,0.2,0.2,0.2]\n",
    "        continuous_cols=cont_cols\n",
    "        mlp_batchnorm=True\n",
    "        pred_dim = 2\n",
    "        model = MD.TabMlp(\n",
    "        mlp_hidden_dims=mlp_hidden_dims,\n",
    "        column_idx=column_idx,\n",
    "        embed_input=embeddings_input,\n",
    "        mlp_dropout=mlp_dropout,\n",
    "        continuous_cols=continuous_cols,\n",
    "        mlp_batchnorm=mlp_batchnorm,\n",
    "        pred_dim = pred_dim)\n",
    "        X_train,X_test,y_train,y_test= train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        random_state=42,\n",
    "                                                        shuffle=True)\n",
    "    \n",
    "        count=Counter(y_train)\n",
    "\n",
    "        class_count=np.array([count[0],count[1]])\n",
    "\n",
    "        weight=1./class_count\n",
    "        samples_weight = np.array([weight[int(t)] for t in y_train])\n",
    "        samples_weight = torch.from_numpy(samples_weight)\n",
    "        sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "        train_subset = torch.utils.data.TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "        val_subset = torch.utils.data.TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        BATCH_SIZE = 256\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        model.to(device);\n",
    "        lr = 0.01\n",
    "        step_size = 10 \n",
    "        gamma=0.1\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "        NUMBER_OF_EPOCHS = 22\n",
    "        train_loader = DataLoader(dataset=train_subset, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "        val_loader = DataLoader(dataset=val_subset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "        with mlflow.start_run() as run:\n",
    "            tr.training(model,optimizer,loss_function,train_loader,val_loader,NUMBER_OF_EPOCHS,device,scheduler)\n",
    "            model.eval()\n",
    "            xt = torch.Tensor(X_test)\n",
    "            xt = xt.to(device)\n",
    "            t = model(xt)\n",
    "            predicted = torch.max(t.data,1)[1]\n",
    "            (f1, acc, recall,precision) = tr.eval_metrics(y_test, predicted.cpu())\n",
    "            model.eval()\n",
    "            xt = torch.Tensor(X_train)\n",
    "            xt = xt.to(device)\n",
    "            t = model(xt)\n",
    "            predicted = torch.max(t.data,1)[1]\n",
    "            (f1t, acct, recallt,precisiont) = tr.eval_metrics(y_train, predicted.cpu())\n",
    "            parametrs = {\n",
    "                \"NUMBER_OF_EPOCHS\":NUMBER_OF_EPOCHS,\n",
    "                \"loss_function\": \"nn.CrossEntropyLoss\",\n",
    "                \"optimizer\":\"Adam\",\n",
    "                \"lr\":lr,\n",
    "                \"step_size\":step_size,\n",
    "                \"gamma\":gamma,\n",
    "                \"BATCH_SIZE\":BATCH_SIZE,\n",
    "                \"mlp_hidden_dims\":mlp_hidden_dims,\n",
    "                \"column_idx\":column_idx,\n",
    "                \"embeddings_input\":embeddings_input,\n",
    "                \"mlp_dropout\":mlp_dropout,\n",
    "                \"continuous_cols\":continuous_cols,\n",
    "                \"mlp_batchnorm\":mlp_batchnorm,\n",
    "                \"pred_dim\":pred_dim,  \n",
    "            }\n",
    "            mlflow.log_param(\"parametrs\", parametrs)\n",
    "            mlflow.log_metric(\"f1\", f1)\n",
    "            mlflow.log_metric(\"acc\", acc)\n",
    "            mlflow.log_metric(\"recall\", recall)\n",
    "            mlflow.log_metric(\"precision\", precision)\n",
    "            mlflow.log_metric(\"f1t\", f1t)\n",
    "            mlflow.log_metric(\"acct\", acct)\n",
    "            mlflow.log_metric(\"recallt\", recallt)\n",
    "            mlflow.log_metric(\"precisiont\", precisiont)\n",
    "            print(f'parametrs : {parametrs}\\nf1 : {f1}\\nacc : {acc}\\nrecall {recall}\\nprecision : {precision}\\\n",
    "            \\nf1t : {f1t}\\nacct : {acct}\\nrecallt {recallt}\\nprecisiont : {precisiont}')\n",
    "\n",
    "            tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "            # Model registry does not work with file store\n",
    "            #os.system(f\"rm -r {model_path}\")\n",
    "            torch.save(model.state_dict(), state_dict_path)\n",
    "            with open(column_idx_path, 'wb') as handle:\n",
    "                pickle.dump(column_idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            with open(embeddings_input_path, 'wb') as handle:\n",
    "                pickle.dump(embeddings_input, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "            with open(cont_cols_path, 'wb') as handle:\n",
    "                pickle.dump(cont_cols, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            python_model=ModelWrapper()\n",
    "            mlflow.pyfunc.log_model(artifact_path =model_path,python_model=python_model,\n",
    "                         artifacts=artifacts,\n",
    "                         conda_env=conda_env)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if tracking_url_type_store != \"file\":\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.pytorch.log_model(model, \"model\", model_name)\n",
    "            else:\n",
    "                mlflow.pytorch.log_model(model, \"model\")\n",
    "            f = open('model_run.txt', mode='wt')\n",
    "            f.write(str(run.info.run_id))\n",
    "            f.close()\n",
    "\n",
    "            os.system(f'mlflow models serve -m \"./mlruns/4/{run.info.run_id}/artifacts/content/Recommendation\" --no-conda -h 0.0.0.0 -p 8080')\n",
    "    else:\n",
    "        os.system(f'mlflow models serve -m \"./mlruns/4/{run_id}/artifacts/content/Recommendation\" --no-conda -h 0.0.0.0 -p 8080')\n",
    "if __name__ == '__main__':\n",
    "    startModel()          \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
