{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoxOjIlOImwx"
      },
      "source": [
        "# Build a Gym Environment\n",
        "\n",
        "This notebook is inspired to the Stable Baselines3 tutorial available at [https://github.com/araffin/rl-tutorial-jnrr19](https://github.com/araffin/rl-tutorial-jnrr19).\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, we will learn how to build a customized environment with **Gymnasium**.\n",
        "\n",
        "### Links\n",
        "\n",
        "Gymnasium Github: [https://github.com/Farama-Foundation/Gymnasium](https://github.com/Farama-Foundation/Gymnasium)\n",
        "\n",
        "Gymnasium Documentation: [https://gymnasium.farama.org/index.html](https://gymnasium.farama.org/index.html#)\n",
        "\n",
        "Stable Baselines 3 Github:[https://github.com/DLR-RM/stable-baselines3](https://github.com/DLR-RM/stable-baselines3)\n",
        "\n",
        "Stable Baseline 3 Documentation: [https://stable-baselines3.readthedocs.io/en/master/](https://stable-baselines3.readthedocs.io/en/master/)\n",
        "\n",
        "## Install Gymnasium and Stable Baselines3 Using Pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sp8rSS4DIhEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb54a1f-73f9-41c2-89d5-a0f9c1d75041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: renderlab in /usr/local/lib/python3.12/dist-packages (0.1.20230421184216)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (from renderlab) (1.0.3)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (from renderlab) (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium->renderlab) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium->renderlab) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium->renderlab) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium->renderlab) (0.0.4)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy->renderlab) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy->renderlab) (4.67.3)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy->renderlab) (2.32.4)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy->renderlab) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy->renderlab) (2.37.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy->renderlab) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy->renderlab) (11.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (2026.1.4)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.12/dist-packages (2.7.1)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (1.2.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.10.0+cu128)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (4.13.0.92)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.19.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (4.67.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (0.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (11.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.78.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (26.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.24.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.0)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3[extra]) (2025.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install renderlab  #For rendering\n",
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fOrkWxmlviA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a633c5bd-3d92-4645-a25c-f9acba6fa045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.3\n",
            "2.7.1\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import renderlab\n",
        "import stable_baselines3\n",
        "\n",
        "print(gym.__version__)\n",
        "print(stable_baselines3.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5ToqdPSfviA5"
      },
      "outputs": [],
      "source": [
        "def evaluate(env, policy, gamma=1., num_episodes=100):\n",
        "    \"\"\"\n",
        "    Evaluate a RL agent\n",
        "    :param env: (Env object) the Gym environment\n",
        "    :param policy: (BasePolicy object) the policy in stable_baselines3\n",
        "    :param gamma: (float) the discount factor\n",
        "    :param num_episodes: (int) number of episodes to evaluate it\n",
        "    :return: (float) Mean reward for the last num_episodes\n",
        "    \"\"\"\n",
        "    all_episode_rewards = []\n",
        "    for i in range(num_episodes): # iterate over the episodes\n",
        "        episode_rewards = []\n",
        "        done = False\n",
        "        discounter = 1.\n",
        "        obs, _ = env.reset()\n",
        "        while not done: # iterate over the steps until termination\n",
        "            action, _ = policy.predict(obs)\n",
        "            obs, reward, terminated, truncated, _ = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            episode_rewards.append(reward * discounter) # compute discounted reward\n",
        "            discounter *= gamma\n",
        "\n",
        "        all_episode_rewards.append(sum(episode_rewards))\n",
        "\n",
        "    mean_episode_reward = np.mean(all_episode_rewards)\n",
        "    std_episode_reward = np.std(all_episode_rewards) / np.sqrt(num_episodes - 1)\n",
        "    print(\"Mean reward:\", mean_episode_reward,\n",
        "          \"Std reward:\", std_episode_reward,\n",
        "          \"Num episodes:\", num_episodes)\n",
        "\n",
        "    return mean_episode_reward, std_episode_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yitpwwp3viA7"
      },
      "source": [
        "## The Minigolf Environment\n",
        "\n",
        "The `Minigolf` environment models a simple problem in which the agent has to hit a ball on a green using a putter in order to reach the hole with the minimum amount of moves.\n",
        "\n",
        "* The green is characterized by a **friction** $f$ that is selected uniformly random at the beginning of each episode in the interval `[0.065, 0.196]` and does not change during the episode.\n",
        "* The **position** of the ball is represented by a unidimensional variable $x_t$ that is initialized uniformly random in the interval `[1,20]`. The observation is made of the pair $s_t = (x_t,f)$.\n",
        "* The **action** $a_t$ is the force applied to the putter and has to be bounded in the interval `[1e-5,5]`. Before being applied the action is subject to a Gaussian noise, so that the actual action $u_t$ applied is given by:\n",
        "\n",
        "$$\n",
        "u_t = a_t + \\epsilon \\qquad \\text{where} \\qquad \\epsilon \\sim \\mathcal{N}(0,\\sigma^2),\n",
        "$$\n",
        "where $\\sigma =0.1$. The movement of the ball is governed by the kinematic law:\n",
        "\n",
        "$$\n",
        "x_{t+1} = x_{t} - v_t \\tau_t + \\frac{1}{2} d \\tau_t^2\n",
        "$$\n",
        "\n",
        "where:\n",
        "* $v_t$ is the velocity computed as $v_t = u_t l$,\n",
        "* $d$ is the deceleration computed as $d = \\frac{5}{7} fg$,\n",
        "* $\\tau_t$ is the time interval computed as $\\tau_t = \\frac{v_t}{d}$.\n",
        "\n",
        "The remaining constants are the putter length $l = 1$ and the gravitational acceleration $g=9.81$. The **episode** terminates when the next state is such that the ball enters or surpasses (without entering) the hole. The **reward** is `-1` at every step and `-100` if the ball surpasses the hole. To check whether the ball will not reach, enter, or surpass the hole, refer to the following condition:\n",
        "\n",
        "\\begin{align*}\n",
        "&v_t < v_{\\min} \\implies \\text{ball does not reach the hole} \\\\\n",
        "&v_t > v_{\\max} \\implies \\text{ball surpasses the hole} \\\\\n",
        "&\\text{otherwise} \\implies \\text{ball enters the hole}\n",
        "\\end{align*}\n",
        "\n",
        "where\n",
        "\n",
        "\\begin{align*}\n",
        "& v_\\min = \\sqrt{\\frac{10}{7} fgx_t}\n",
        "& v_\\max = \\sqrt{ \\frac{g(2 h - \\rho)^2}{2r} + v_\\min^2},\n",
        "\\end{align*}\n",
        "where $h = 0.1$ is the hole size and $\\rho = 0.02135$ is the ball radius.\n",
        "\n",
        "\n",
        "**References**\n",
        "\n",
        "Penner, A. R. \"The physics of putting.\" Canadian Journal of Physics 80.2 (2002): 83-96."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_QiBx81viA8"
      },
      "source": [
        "## Exercise 1\n",
        "\n",
        "Complete the constructor `__init__`, methods `reset` and `step` based on the environment description provided above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y1JZ2BDoviA8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gymnasium.spaces import Box\n",
        "\n",
        "class Minigolf(gym.Env):\n",
        "    \"\"\"\n",
        "    The Minigolf problem.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Minigolf, self).__init__()\n",
        "\n",
        "        # Constants\n",
        "        self.min_pos, self.max_pos = 1.0, 20.0\n",
        "        self.min_action, self.max_action = 1e-5, 5.0\n",
        "        self.min_friction, self.max_friction = 0.065, 0.196\n",
        "        self.putter_length = 1.0\n",
        "        self.hole_size = 0.10\n",
        "        self.sigma_noise = 0.1\n",
        "        self.ball_radius = 0.02135\n",
        "        self.g = 9.81\n",
        "\n",
        "\n",
        "        # Instance the spaces\n",
        "        low = np.array([self.min_pos, self.min_friction])\n",
        "        high = np.array([self.max_pos, self.max_friction])\n",
        "\n",
        "        self.action_space = Box(low=self.min_action,\n",
        "                                high=self.max_action,\n",
        "                                shape=(1,),\n",
        "                                dtype=np.float32)\n",
        "\n",
        "        self.observation_space = Box(low=low,\n",
        "                                     high=high,\n",
        "                                     shape=(2,),\n",
        "                                     dtype=np.float32)\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        #Retrieve the state components\n",
        "        x, friction = self.state\n",
        "\n",
        "        # Clip the action within the allowed range\n",
        "        action = np.clip(action, self.min_action, self.max_action)\n",
        "\n",
        "        # TODO Add noise to the action\n",
        "        # if type(action) == float:\n",
        "        #   uaction = action + np.random.normal(0, self.sigma_noise)\n",
        "        # else:\n",
        "        #   uaction = action[0] + np.random.normal(0, self.sigma_noise)\n",
        "        # # TODO Compute the speed\n",
        "        uaction = float(action) + np.random.normal(0, self.sigma_noise)\n",
        "        vt = self.putter_length * uaction\n",
        "\n",
        "\n",
        "        # Compute the speed limits\n",
        "        v_min = np.sqrt(10 / 7 * friction * 9.81 * x)\n",
        "        v_max = np.sqrt((2 * self.hole_size - self.ball_radius) ** 2 \\\n",
        "                        * (9.81 / (2 * self.ball_radius)) + v_min ** 2)\n",
        "\n",
        "        # TODO Compute the deceleration\n",
        "        d = 5/7 * self.g * friction\n",
        "\n",
        "        # TODO Compute the time interval\n",
        "        T = vt/d\n",
        "        # TODO Update the position\n",
        "        xt_next = x - vt*T + 1/2 * d * T**2\n",
        "\n",
        "        # Clip the position\n",
        "        x = np.clip(xt_next, self.min_pos, self.max_pos)\n",
        "\n",
        "        # TODO Compute the reward and episode termination (done)\n",
        "        if vt > v_max:\n",
        "          done = True\n",
        "          reward = -100\n",
        "        elif vt < v_min:\n",
        "          done = False\n",
        "          reward = -1\n",
        "        else:\n",
        "          done = True\n",
        "          reward = 0\n",
        "\n",
        "\n",
        "        self.state = np.array([x, friction]).astype(np.float32)\n",
        "\n",
        "        return self.state, reward, done, False, {}\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "\n",
        "        # TODO Random generation of initial position and friction\n",
        "               # Instance the spaces\n",
        "        if seed is not None:\n",
        "          np.random.seed(seed)\n",
        "        x = np.random.uniform(self.min_pos, self.max_pos)\n",
        "        friction = np.random.uniform(self.min_friction, self.max_friction)\n",
        "        #print(x, friction)\n",
        "\n",
        "        self.state = np.array([x, friction]).astype(np.float32)\n",
        "\n",
        "        return self.state, {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7FkSAMFviA9"
      },
      "source": [
        "To be able to instance the environment with `gym.make`, we need to register the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DG9IBUduviA9"
      },
      "outputs": [],
      "source": [
        "from gymnasium.envs.registration import register\n",
        "\n",
        "register(\n",
        "    id=\"Minigolf-v1\",\n",
        "    entry_point=\"__main__:Minigolf\",\n",
        "    max_episode_steps=20,\n",
        "    reward_threshold=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZGORKvzviA-"
      },
      "source": [
        "### Validate the environment\n",
        "\n",
        "Stable Baselines3 provides a [helper](https://stable-baselines3.readthedocs.io/en/master/common/env_checker.html) to check that our environment complies with the Gym interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iUcLpum-viA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85cfc199-5f8a-45da-956e-28d2409d00e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/gymnasium/spaces/box.py:236: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/gymnasium/spaces/box.py:306: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/env_checker.py:507: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
            "  warnings.warn(\n",
            "\n",
            "WARNING:py.warnings:/tmp/ipython-input-3098968962.py:53: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  uaction = float(action) + np.random.normal(0, self.sigma_noise)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.env_checker import check_env\n",
        "\n",
        "env = Minigolf()\n",
        "\n",
        "# If the environment don't follow the interface, an error will be thrown\n",
        "check_env(env, warn=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU1GzuXMviA-"
      },
      "source": [
        "## Evaluate some simple Policies\n",
        "\n",
        "* **Do-nothing policy**: a policy plays the zero action.\n",
        "\n",
        "$$\n",
        "\\pi(s) = 0\n",
        "$$\n",
        "\n",
        "\n",
        "* **Max-action policy**: a policy that plays the maximum available actions.\n",
        "\n",
        "$$\n",
        "\\pi(s) = +\\infty\n",
        "$$\n",
        "\n",
        "\n",
        "* **Zero-mean Gaussian policy**: a policy that selects the action sampled from a Gaussian policy with zero mean and variance $\\sigma^2=1$\n",
        "\n",
        "$$\n",
        "\\pi(a|s) = \\mathcal{N}(0,\\sigma^2)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uWLRtOzRviA_"
      },
      "outputs": [],
      "source": [
        "class DoNothingPolicy():\n",
        "\n",
        "    def predict(self, obs):\n",
        "        return 0, obs\n",
        "\n",
        "\n",
        "class MaxActionPolicy():\n",
        "\n",
        "    def predict(self, obs):\n",
        "        return np.inf, obs\n",
        "\n",
        "\n",
        "class ZeroMeanGaussianPolicy():\n",
        "\n",
        "    def predict(self, obs):\n",
        "        return np.random.randn(), obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D7zdbEzdviA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6856e70f-d995-470f-cd54-89023a6ee467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean reward: -20.0 Std reward: 0.0 Num episodes: 100\n",
            "Mean reward: -78.29 Std reward: 4.1717979313238525 Num episodes: 100\n",
            "Mean reward: -18.42 Std reward: 0.4015575735165319 Num episodes: 100\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"Minigolf-v1\")\n",
        "\n",
        "do_nothing_policy = DoNothingPolicy()\n",
        "\n",
        "max_action_policy = MaxActionPolicy()\n",
        "\n",
        "gauss_policy = ZeroMeanGaussianPolicy()\n",
        "\n",
        "\n",
        "do_nothing_mean, do_nothing_std = evaluate(env, do_nothing_policy)\n",
        "max_action_mean, max_action_std = evaluate(env, max_action_policy)\n",
        "gauss_policy_mean, gauss_policy_std = evaluate(env, gauss_policy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qoWWQKeviA_"
      },
      "source": [
        "## Train PPO, DDPG, and SAC\n",
        "\n",
        "We now train three algorithms suitable for environments with continuous actions: [Proximal Policy Optimization](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html), [Deep Deterministic Policy Gradient](https://stable-baselines3.readthedocs.io/en/master/modules/ddpg.html), and [Soft Actor Critic](https://stable-baselines3.readthedocs.io/en/master/modules/sac.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JICM9YhjviBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "efe3c9986a3b4406944210f0fcce65b5",
            "89ad7dbbfccf49aea5b3a9267320b0fd",
            "1bca82c6b55047bdbf34fa54f2419990",
            "fd5245cbaf3d4b789cc611b8a9291826",
            "0b06215cb01f4e59b2f3c3f50b779b90",
            "f500f3959c2d40d88e8129655540c844"
          ]
        },
        "outputId": "19fe1b02-fee3-49ad-a7f9-e280c5aebc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efe3c9986a3b4406944210f0fcce65b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/ipywidgets/widgets/widget_output.py:111: DeprecationWarning: Kernel._parent_header is deprecated in ipykernel 6. Use .get_parent()\n",
            "  if ip and hasattr(ip, 'kernel') and hasattr(ip.kernel, '_parent_header'):\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "PPO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/tmp/ipython-input-3098968962.py:53: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  uaction = float(action) + np.random.normal(0, self.sigma_noise)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 15.5         |\n",
            "|    ep_rew_mean          | -14.9        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 536          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 15           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068355724 |\n",
            "|    clip_fraction        | 0.0841       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | 0.162        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 72.3         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00802     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 55.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 12.9         |\n",
            "|    ep_rew_mean          | -17.1        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 508          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059513836 |\n",
            "|    clip_fraction        | 0.0686       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.146        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 48.5         |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00624     |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 136          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 8.51         |\n",
            "|    ep_rew_mean          | -13.6        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 503          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070550255 |\n",
            "|    clip_fraction        | 0.0972       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.36        |\n",
            "|    explained_variance   | 0.059        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 68.6         |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00735     |\n",
            "|    std                  | 0.937        |\n",
            "|    value_loss           | 170          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 8.09         |\n",
            "|    ep_rew_mean          | -11.1        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 500          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 65           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012194135 |\n",
            "|    clip_fraction        | 0.0022       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.0309       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 32.6         |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00173     |\n",
            "|    std                  | 0.86         |\n",
            "|    value_loss           | 248          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.2         |\n",
            "|    ep_rew_mean          | -8.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 485         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013178872 |\n",
            "|    clip_fraction        | 0.148       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.19       |\n",
            "|    explained_variance   | 0.0471      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 84.2        |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0134     |\n",
            "|    std                  | 0.79        |\n",
            "|    value_loss           | 121         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 4.69         |\n",
            "|    ep_rew_mean          | -7.69        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 488          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 100          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026478954 |\n",
            "|    clip_fraction        | 0.00391      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.12        |\n",
            "|    explained_variance   | 0.016        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 114          |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00223     |\n",
            "|    std                  | 0.732        |\n",
            "|    value_loss           | 262          |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bca82c6b55047bdbf34fa54f2419990"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.57     |\n",
            "|    ep_rew_mean     | -12.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 1024     |\n",
            "|    fps             | 159      |\n",
            "|    time_elapsed    | 62       |\n",
            "|    total_timesteps | 9880     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.9     |\n",
            "|    critic_loss     | 12.6     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9779     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 6.67     |\n",
            "|    ep_rew_mean     | -5.67    |\n",
            "| time/              |          |\n",
            "|    episodes        | 2048     |\n",
            "|    fps             | 158      |\n",
            "|    time_elapsed    | 96       |\n",
            "|    total_timesteps | 15324    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.52     |\n",
            "|    critic_loss     | 5.51     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 15223    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 4.2      |\n",
            "|    ep_rew_mean     | -3.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 3072     |\n",
            "|    fps             | 157      |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total_timesteps | 19360    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.89     |\n",
            "|    critic_loss     | 26       |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 19259    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 7.24     |\n",
            "|    ep_rew_mean     | -6.42    |\n",
            "| time/              |          |\n",
            "|    episodes        | 4096     |\n",
            "|    fps             | 157      |\n",
            "|    time_elapsed    | 152      |\n",
            "|    total_timesteps | 24017    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.13     |\n",
            "|    critic_loss     | 12.6     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 23916    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 6.98     |\n",
            "|    ep_rew_mean     | -6.19    |\n",
            "| time/              |          |\n",
            "|    episodes        | 5120     |\n",
            "|    fps             | 156      |\n",
            "|    time_elapsed    | 205      |\n",
            "|    total_timesteps | 32255    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.293   |\n",
            "|    critic_loss     | 35.5     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 32154    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.27     |\n",
            "|    ep_rew_mean     | -1.27    |\n",
            "| time/              |          |\n",
            "|    episodes        | 6144     |\n",
            "|    fps             | 156      |\n",
            "|    time_elapsed    | 259      |\n",
            "|    total_timesteps | 40769    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.0744  |\n",
            "|    critic_loss     | 7.9      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 40668    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.83     |\n",
            "|    ep_rew_mean     | -0.83    |\n",
            "| time/              |          |\n",
            "|    episodes        | 7168     |\n",
            "|    fps             | 156      |\n",
            "|    time_elapsed    | 271      |\n",
            "|    total_timesteps | 42588    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.517    |\n",
            "|    critic_loss     | 4.87     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 42487    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.73     |\n",
            "|    ep_rew_mean     | -0.73    |\n",
            "| time/              |          |\n",
            "|    episodes        | 8192     |\n",
            "|    fps             | 156      |\n",
            "|    time_elapsed    | 282      |\n",
            "|    total_timesteps | 44391    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.881    |\n",
            "|    critic_loss     | 2.17     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 44290    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.6      |\n",
            "|    ep_rew_mean     | -0.6     |\n",
            "| time/              |          |\n",
            "|    episodes        | 9216     |\n",
            "|    fps             | 156      |\n",
            "|    time_elapsed    | 293      |\n",
            "|    total_timesteps | 46110    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.14     |\n",
            "|    critic_loss     | 9.49     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 46009    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.68     |\n",
            "|    ep_rew_mean     | -0.68    |\n",
            "| time/              |          |\n",
            "|    episodes        | 10240    |\n",
            "|    fps             | 156      |\n",
            "|    time_elapsed    | 305      |\n",
            "|    total_timesteps | 47915    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.22     |\n",
            "|    critic_loss     | 27.1     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 47814    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.82     |\n",
            "|    ep_rew_mean     | -0.82    |\n",
            "| time/              |          |\n",
            "|    episodes        | 11264    |\n",
            "|    fps             | 156      |\n",
            "|    time_elapsed    | 317      |\n",
            "|    total_timesteps | 49730    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.885    |\n",
            "|    critic_loss     | 24       |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 49629    |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b06215cb01f4e59b2f3c3f50b779b90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAC\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 6.82     |\n",
            "|    ep_rew_mean     | -5.83    |\n",
            "| time/              |          |\n",
            "|    episodes        | 2048     |\n",
            "|    fps             | 89       |\n",
            "|    time_elapsed    | 275      |\n",
            "|    total_timesteps | 24534    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 23       |\n",
            "|    critic_loss     | 39.1     |\n",
            "|    ent_coef        | 0.182    |\n",
            "|    ent_coef_loss   | 0.1      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 24433    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.93     |\n",
            "|    ep_rew_mean     | -2.93    |\n",
            "| time/              |          |\n",
            "|    episodes        | 4096     |\n",
            "|    fps             | 89       |\n",
            "|    time_elapsed    | 386      |\n",
            "|    total_timesteps | 34443    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.94     |\n",
            "|    critic_loss     | 21.7     |\n",
            "|    ent_coef        | 0.214    |\n",
            "|    ent_coef_loss   | 0.0272   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 34342    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.04     |\n",
            "|    ep_rew_mean     | -3.04    |\n",
            "| time/              |          |\n",
            "|    episodes        | 6144     |\n",
            "|    fps             | 88       |\n",
            "|    time_elapsed    | 467      |\n",
            "|    total_timesteps | 41505    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.85     |\n",
            "|    critic_loss     | 15.3     |\n",
            "|    ent_coef        | 0.293    |\n",
            "|    ent_coef_loss   | 0.107    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 41404    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.37     |\n",
            "|    ep_rew_mean     | -2.37    |\n",
            "| time/              |          |\n",
            "|    episodes        | 8192     |\n",
            "|    fps             | 88       |\n",
            "|    time_elapsed    | 543      |\n",
            "|    total_timesteps | 48278    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.57     |\n",
            "|    critic_loss     | 28.1     |\n",
            "|    ent_coef        | 0.372    |\n",
            "|    ent_coef_loss   | -0.00202 |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 48177    |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.sac.sac.SAC at 0x7eb781f21580>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from stable_baselines3 import PPO, DDPG, SAC\n",
        "\n",
        "\n",
        "# Separate evaluation env\n",
        "eval_env = gym.make('Minigolf-v1')\n",
        "\n",
        "ppo = PPO(\"MlpPolicy\", env, verbose=1, policy_kwargs=dict(net_arch=[32]))\n",
        "ddpg = DDPG(\"MlpPolicy\", env, verbose=1, policy_kwargs=dict(net_arch=[32]))\n",
        "sac = SAC(\"MlpPolicy\", env, verbose=1, policy_kwargs=dict(net_arch=[32]))\n",
        "\n",
        "print('PPO')\n",
        "ppo.learn(total_timesteps=50000, log_interval=4, progress_bar=True)\n",
        "\n",
        "print('DDPG')\n",
        "ddpg.learn(total_timesteps=50000, log_interval=1024, progress_bar=True)\n",
        "\n",
        "print('SAC')\n",
        "sac.learn(total_timesteps=50000, log_interval=2048, progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_bTprXqviBA"
      },
      "source": [
        "Let us now evaluate the results of the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6K570AdaviBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa839945-2630-48c0-e320-bc45f5a33f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/tmp/ipython-input-3098968962.py:53: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  uaction = float(action) + np.random.normal(0, self.sigma_noise)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean reward: -6.19 Std reward: 1.7375063403706712 Num episodes: 100\n",
            "Mean reward: -0.81 Std reward: 0.06307763374436204 Num episodes: 100\n",
            "Mean reward: -2.13 Std reward: 0.15805318117901987 Num episodes: 100\n"
          ]
        }
      ],
      "source": [
        "ppo_mean, ppo_std = evaluate(eval_env, ppo)\n",
        "ddpg_mean, ddpg_std = evaluate(eval_env, ddpg)\n",
        "sac_mean, sac_std = evaluate(eval_env, sac)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "efe3c9986a3b4406944210f0fcce65b5": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_89ad7dbbfccf49aea5b3a9267320b0fd",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m\u001b[0m \u001b[32m51,182/50,000 \u001b[0m [ \u001b[33m0:01:43\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m490 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\"></span> <span style=\"color: #008000; text-decoration-color: #008000\">51,182/50,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:01:43</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">490 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "89ad7dbbfccf49aea5b3a9267320b0fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bca82c6b55047bdbf34fa54f2419990": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_fd5245cbaf3d4b789cc611b8a9291826",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m\u001b[0m\u001b[38;2;249;38;114m\u001b[0m \u001b[32m49,983/50,000 \u001b[0m [ \u001b[33m0:05:18\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m157 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\"></span> <span style=\"color: #008000; text-decoration-color: #008000\">49,983/50,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:05:18</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">157 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "fd5245cbaf3d4b789cc611b8a9291826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b06215cb01f4e59b2f3c3f50b779b90": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f500f3959c2d40d88e8129655540c844",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m\u001b[0m\u001b[38;2;249;38;114m\u001b[0m \u001b[32m49,987/50,000 \u001b[0m [ \u001b[33m0:09:22\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m89 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\"></span> <span style=\"color: #008000; text-decoration-color: #008000\">49,987/50,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:09:22</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">89 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "f500f3959c2d40d88e8129655540c844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}